{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import os\n",
    "import math\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import optimize\n",
    "from scipy import stats\n",
    "import sympy as sy\n",
    "from numpy import matrix\n",
    "import signal\n",
    "from scipy.optimize import brentq as root\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def normalize_column(df2,reads,channels,string):\n",
    "    df1=df2[df2['Search ID'] == string][channels]\n",
    "    df1.columns=reads\n",
    "    df1=df1.reset_index(drop=True)\n",
    "    temp1=list(df1['37'].values)\n",
    "    for i in reads:\n",
    "        temp=df1[i].values/temp1\n",
    "        df1[i]=temp\n",
    "    Seq=df2[df2['Search ID'] == string][[\"Sequence\", \"Protein Group Accessions\"]]\n",
    "    Seq=Seq.reset_index(drop=True)\n",
    "    return df1,Seq\n",
    "\n",
    "def fctSigmoidTR0(x,Pl,a,b):\n",
    "    return (1 - Pl)*1/(1+np.exp(-(a/x-b))) + Pl\n",
    "\n",
    "def fctSigmoidTR1(x,Pl,a,b):\n",
    "    return -((1 - Pl) * (np.exp(-(a/x - b)) * (a/x**2))/(1 + np.exp(-(a/x - b)))**2)\n",
    "\n",
    "def fctSigmoidTR2(x,Pl,a,b):\n",
    "    return -((1 - Pl) * 1 * (np.exp(-(a/x - b)) * (a/x**2) * (a/x**2) - np.exp(-(a/x - b)) * (a * (2 * x)/(x**2)**2))/(1 + np.exp(-(a/x - b)))**2 - (1 - Pl) * 1 * (np.exp(-(a/x - b)) * (a/x**2)) *(2 * (np.exp(-(a/x - b)) * (a/x**2) * (1 + np.exp(-(a/x - b)))))/((1 + np.exp(-(a/x - b)))**2)**2)\n",
    "\n",
    "\n",
    "startPars=[0, 550, 10]\n",
    "\n",
    "def rSquared(y,z):\n",
    "#     y=[i for i in y if not(np.isnan(i))]\n",
    "#     z=[i for i in z if not(np.isnan(i))]\n",
    "    y=np.array(y)\n",
    "    z=np.array(z)\n",
    "    ssTot = np.nansum((y - np.nanmean(y))**2)\n",
    "    ssRes = np.nansum((y - z)**2)\n",
    "    r2 = 1 - (ssRes/ssTot)\n",
    "    return r2\n",
    "\n",
    "def fitSigmoidTR(xVec, yVec, startPars, maxAttempts, fixT0=True, method=None):\n",
    "    varyPars = 0\n",
    "    attempts = 0\n",
    "    repeatLoop = True\n",
    "    validValues = []\n",
    "    m=1234\n",
    "    for i in yVec:\n",
    "        if math.isnan(float(i)):\n",
    "            validValues.append(0)\n",
    "        else:\n",
    "            validValues.append(1)\n",
    "    if sum(validValues) <=2:\n",
    "        m = [float('nan'),float('nan')]\n",
    "        r_squared=0\n",
    "    else:\n",
    "        yVec=[yVec[i] for i in range(0,len(yVec)) if validValues[i] == 1]\n",
    "        xVec=[xVec[i] for i in range(0,len(xVec)) if validValues[i] == 1]\n",
    "        while (repeatLoop & (attempts < maxAttempts)):\n",
    "            temp=(1 + varyPars*(np.random.uniform(-0.2, 0.2,(1,))[0]))\n",
    "            parTmp = [i*temp for i in startPars]\n",
    "            try:\n",
    "                m=optimize.curve_fit(fctSigmoidTR0,xVec,yVec, parTmp, check_finite=False, bounds=([0.0,1e-5,1e-5], [1.5, 15000, 250]), method=method)\n",
    "                attempts = attempts + 1\n",
    "                varyPars = 1\n",
    "                if not(all(np.isnan(m[0]))):\n",
    "                    repeatLoop = False\n",
    "            except RuntimeError,ValueError:\n",
    "                m = [float('nan'),float('nan')]\n",
    "                r_squared=0\n",
    "        residuals = yVec- fctSigmoidTR0(xVec, m[0][0],m[0][1],m[0][2])\n",
    "        ss_res = np.nansum(residuals**2)\n",
    "        ss_tot = np.nansum((yVec-np.nanmean(xVec))**2)\n",
    "        r_squared = 1 - (ss_res / ss_tot)\n",
    "    return m[0],r_squared\n",
    "\n",
    "def plot_fit(df,joint, xVec,startPars,title,plot=False):\n",
    "    anorm=df.ix[joint]\n",
    "    anorm = anorm[(((anorm.iloc[0:,6] < 0.6) & (anorm.iloc[0:,6] > 0.4)) & ((anorm.iloc[0:,8] < 0.3) & (anorm.iloc[0:,9] < 0.2)))]\n",
    "    a=anorm.median(0)\n",
    "    afitmodel,rsquared=fitSigmoidTR(xVec, a, startPars, 500, fixT0=True)\n",
    "    afit=[]\n",
    "    for i in temps:\n",
    "        afit.append(fctSigmoidTR0(i,afitmodel[0],afitmodel[1],afitmodel[2]))\n",
    "    r2=rSquared(a,afit)\n",
    "    if plot == True:\n",
    "        plt.scatter(xVec,a)\n",
    "        plt.plot(xVec,afit)\n",
    "        plt.xlim(35,66)\n",
    "        plt.xlabel('Temperature')\n",
    "        plt.ylabel('Fold Change')\n",
    "        plt.title(title+'\\n'+'R-Squared (noSUM): '+str(rsquared)+'\\n'+'R-Squared (SUM): '+str(r2))\n",
    "        plt.savefig('Figures/'+title+ ' Fit Plot.png')\n",
    "        plt.show\n",
    "    return a.tolist(),afit,afitmodel,rsquared,r2\n",
    "\n",
    "def scale_factor(val1,fit1,r1,val2,fit2,r2):\n",
    "    if r1 > r2:\n",
    "        normcurve = fit1\n",
    "    else:\n",
    "        normcurve = fit2\n",
    "\n",
    "    val1coeff=[normcurve[i]/val1[i] for i in range(0,len(val1))]\n",
    "    val2coeff=[normcurve[i]/val2[i] for i in range(0,len(val2))]\n",
    "    return val1coeff,val2coeff\n",
    "\n",
    "def meltingPoint(model,xRange):\n",
    "    try:\n",
    "        if (model[1] == 0):\n",
    "            r=float('nan')\n",
    "        else:\n",
    "            Pl=model[0][0]\n",
    "            a=model[0][1]\n",
    "            b=model[0][2]\n",
    "            def calc(i):\n",
    "                return fctSigmoidTR0(i,Pl,a,b)-0.5\n",
    "            r=root(calc,min(xRange),max(xRange))\n",
    "    except ValueError:\n",
    "        r=float('nan')\n",
    "    return r\n",
    "\n",
    "def inflectionPoint(model,xRange):\n",
    "    try:\n",
    "        if (model[1] == 0):\n",
    "            r=float('nan')\n",
    "        else:\n",
    "            Pl=model[0][0]\n",
    "            a=model[0][1]\n",
    "            b=model[0][2]\n",
    "            def calc(i):\n",
    "                return fctSigmoidTR2(i,Pl,a,b)\n",
    "            r=root(calc,min(xRange),max(xRange))\n",
    "    except ValueError:\n",
    "        r=float('nan')\n",
    "    return r\n",
    "\n",
    "def meltingCurveSlope(model, xInfl):\n",
    "    try:\n",
    "        if (model[1] == 0):\n",
    "            r=float('nan')\n",
    "        else:\n",
    "            Pl=model[0][0]\n",
    "            a=model[0][1]\n",
    "            b=model[0][2]\n",
    "            r=fctSigmoidTR1(xInfl,Pl,a,b)\n",
    "    except ValueError:\n",
    "        r=float('nan')\n",
    "    return r\n",
    "\n",
    "def timeout(signum, frame):\n",
    "#     print('TimeOut, changing method')\n",
    "    raise Exception('changing method')\n",
    "\n",
    "def fitting(df1,temps,startPars,title,df_info):\n",
    "    df_fit = pd.DataFrame(columns=df1.columns,index=range(0,len(df1.index)))\n",
    "    df_fit.columns=[title+'_'+str(df1.columns[i]) for i in range(0,len(df1.columns))]\n",
    "    df_param=pd.DataFrame(columns=range(0,3),index=range(0,len(df1.index)))\n",
    "    df_param.columns=[title+'_'+i for i in ['Pl','a','b']]\n",
    "    df_R=[float('nan')]*len(df1.index)\n",
    "    df_min=[float('nan')]*len(df1.index)\n",
    "    df_infl=[float('nan')]*len(df1.index)\n",
    "    df_slope=[float('nan')]*len(df1.index)\n",
    "    colnames=[title+'_'+i for i in ['R','min','infl','slope']]\n",
    "    for i in range(0,len(df1.index)):\n",
    "#     for i in range(0,25):\n",
    "        if i%1000==0:\n",
    "            print(title+'_'+str(i))\n",
    "        pts = df1.ix[i].tolist()\n",
    "        validValues=[]\n",
    "        for k in pts:\n",
    "            if math.isnan(float(k)):\n",
    "                validValues.append(0)\n",
    "            else:\n",
    "                validValues.append(1)\n",
    "        pts1=pts\n",
    "        pts=[pts[k] for k in range(0,len(pts)) if validValues[k] == 1]\n",
    "        temps1=[temps[k] for k in range(0,len(temps)) if validValues[k] == 1]\n",
    "        \n",
    "        if sum(validValues) <= 2:\n",
    "            continue\n",
    "        else:\n",
    "            signal.signal(signal.SIGALRM, timeout)\n",
    "            signal.alarm(2)\n",
    "            try:\n",
    "                dffitmodel = fitSigmoidTR(temps1, pts, startPars, 500, fixT0=True)\n",
    "            except Exception:\n",
    "                signal.signal(signal.SIGALRM, timeout)\n",
    "                signal.alarm(2)\n",
    "                try:\n",
    "                    dffitmodel = fitSigmoidTR(temps1, pts, startPars, 500, fixT0=True, method='dogbox')\n",
    "                except Exception:\n",
    "                    signal.signal(signal.SIGALRM, timeout)\n",
    "                    signal.alarm(2)\n",
    "                    try:\n",
    "                        dffitmodel = fitSigmoidTR(temps1, pts, startPars, 500, fixT0=True, method='trf')\n",
    "                    except Exception:\n",
    "                        print('Notfound '+title+'_'+str(i))\n",
    "                        dffitmodel = [float('nan'),float('nan')]\n",
    "            if not(np.isnan(dffitmodel[1])):\n",
    "                df_param.ix[i]=list(dffitmodel[0])\n",
    "                dffit=[float('nan')] * len(temps)\n",
    "                for j in range(0,len(temps)):\n",
    "                    if validValues[j] == 1:\n",
    "                        dffit[j]=fctSigmoidTR0(temps[j],dffitmodel[0][0],dffitmodel[0][1],dffitmodel[0][2])\n",
    "                df_fit.ix[i]=dffit\n",
    "                dffit=[dffit[k] for k in range(0,len(dffit)) if validValues[k] == 1]\n",
    "                slope1, intercept1, r_value1, p_value1, std_err1 = sp.stats.linregress(pts,dffit)\n",
    "                df_R[i]=r_value1**2\n",
    "#                 df_R[i]=rSquared(pts1,df_fit.ix[i].tolist())\n",
    "                df_min[i]=meltingPoint(dffitmodel,temps1)\n",
    "                df_infl[i]=inflectionPoint(dffitmodel,temps1)\n",
    "                df_slope[i]=meltingCurveSlope(dffitmodel, df_infl[i])\n",
    "            else:\n",
    "                continue\n",
    "    df_res=pd.concat([df_fit,df_param],1)\n",
    "    df_res[colnames[0]]=df_R\n",
    "    df_res[colnames[1]]=df_min\n",
    "    df_res[colnames[2]]=df_infl\n",
    "    df_res[colnames[3]]=df_slope\n",
    "    df_info=df_info.reset_index(drop=True)\n",
    "    df_res=pd.concat([df_info,df_res],1)\n",
    "    df_res.to_csv('../Result_dup/'+title+'_'+'fitting_aggr.csv',index=False)\n",
    "    return df_fit,df_param,df_R,df_min,df_infl,df_slope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#INIT\n",
    "data=pd.read_csv('GMRJ1511B and GMRJ1512A 24vs28 Joint Accessions_30_New Export_2016-05-19_psms.txt',sep='\\t')\n",
    "mycols=[2,4,5,7,10,19, 20, 22, 24, 26,28,30, 32, 34, 36, 39, 45, 47, 49,51]\n",
    "mycols=[i-1 for i in mycols]\n",
    "dataReduced=data[data.columns[mycols]]\n",
    "ctrl1Name='E'\n",
    "treated1Name='G'\n",
    "ctrl2Name='F'\n",
    "treated2Name='H'\n",
    "ctrl3Name='I'\n",
    "treated3Name='J'\n",
    "dataReduced=dataReduced[dataReduced['Quan Usage'] == 'Used']\n",
    "dataReduced=dataReduced[dataReduced['Isolation Interference [%]'] <= 30].reset_index(drop=True)\n",
    "reads = [\"37\", \"40\", \"43\", \"46\", \"49\", \"52\", \"55\", \"58\", \"61\", \"64\"]\n",
    "channels = [\"126\", \"127_N\", \"127_C\", \"128_N\", \"128_C\", \"129_N\", \"129_C\", \"130_N\", \"130_C\", \"131\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ctrl1,ctrl1seq=normalize_column(dataReduced,reads,channels,ctrl1Name)\n",
    "treated1,treated1seq=normalize_column(dataReduced,reads,channels,treated1Name)\n",
    "ctrl2,ctrl2seq=normalize_column(dataReduced,reads,channels,ctrl2Name)\n",
    "treated2,treated2seq=normalize_column(dataReduced,reads,channels,treated2Name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Pgroups=dataReduced.drop_duplicates('Protein Group Accessions')['Protein Group Accessions']\n",
    "Protein_desc=dataReduced.drop_duplicates('Protein Group Accessions')['Protein Descriptions']\n",
    "Desc=[]\n",
    "gene_name=[]\n",
    "for i in Protein_desc:\n",
    "    temp=i.split('OS')\n",
    "    Desc.append(temp[0][0:-1])\n",
    "    result=re.search(\".*?GN=(.*?) .*\", temp[1])\n",
    "    try:\n",
    "        gene_name.append(result.group(1))\n",
    "    except AttributeError:\n",
    "        gene_name.append(i)\n",
    "Pgroups=pd.DataFrame([Pgroups.tolist(),Desc,gene_name]).T\n",
    "Pgroups.columns=[\"Protein Group Accessions\", \"Protein_Description\", \"Gene_Name\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Seqs=dataReduced.drop_duplicates('Sequence')[['Unique Sequence ID','Sequence',\"Protein Group Accessions\"]]\n",
    "Seqs.columns=[\"Unique_Sequence_ID\", \"Sequence\", \"Protein_Group_Accessions\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "temps=[37,40,43,46,49,52,55,58,61,64]\n",
    "ctrl1Read=list(ctrl1.index)\n",
    "treated1Read=list(treated1.index)\n",
    "ctrl2Read=list(ctrl2.index)\n",
    "treated2Read=list(treated2.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "joint1=list(set(ctrl1Read).intersection(treated1Read))\n",
    "joint2=list(set(ctrl2Read).intersection(treated2Read))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a,afit,afitmodel,rsquared,ar=plot_fit(ctrl1,joint1,temps,startPars,'ctrl1')\n",
    "b,bfit,bfitmodel,rsquared,br=plot_fit(treated1,joint1,temps,startPars,'treated1')\n",
    "c,cfit,cfitmodel,rsquared,cr=plot_fit(ctrl2,joint2,temps,startPars,'ctrl2')\n",
    "d,dfit,dfitmodel,rsquared,dr=plot_fit(treated2,joint2,temps,startPars,'treated2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "acoeff,bcoeff=scale_factor(a,afit,ar,b,bfit,br)\n",
    "ccoeff,dcoeff=scale_factor(c,cfit,cr,d,dfit,dr)\n",
    "allcoeff=pd.DataFrame([acoeff,bcoeff,ccoeff,dcoeff],columns=reads,index=['a.coeff','b.coeff','c.coeff','d.coeff'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ctrl1norm=ctrl1*acoeff\n",
    "ctrl2norm=ctrl2*ccoeff\n",
    "treated1norm=treated1*bcoeff\n",
    "treated2norm=treated2*dcoeff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ctrl1Unorm=pd.concat([ctrl1seq,ctrl1norm], 1).groupby('Sequence').median()\n",
    "treated1Unorm=pd.concat([treated1seq,treated1norm], 1).groupby('Sequence').median()\n",
    "ctrl2Unorm=pd.concat([ctrl2seq,ctrl2norm], 1).groupby('Sequence').median()\n",
    "treated2Unorm=pd.concat([treated2seq,treated2norm], 1).groupby('Sequence').median()\n",
    "combinedUnorm=pd.concat([ctrl1Unorm,treated1Unorm,ctrl2Unorm,treated2Unorm],1)\n",
    "combinedUnorm['Protein_Group_Accessions']=Seqs[Seqs['Sequence'].isin(combinedUnorm.index)].sort_values('Sequence')['Protein_Group_Accessions'].tolist()\n",
    "combinedUnorm=combinedUnorm.groupby('Protein_Group_Accessions').median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ctrl1norm=combinedUnorm.iloc[:,0:10]\n",
    "treated1norm=combinedUnorm.iloc[:,10:20]\n",
    "ctrl2norm=combinedUnorm.iloc[:,20:30]\n",
    "treated2norm=combinedUnorm.iloc[:,30:40]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "UniProt_Accession = set(combinedUnorm.index).intersection(Pgroups['Protein Group Accessions'])\n",
    "Pgroups=Pgroups[Pgroups['Protein Group Accessions'].isin(UniProt_Accession)].sort_values('Protein Group Accessions')\n",
    "Pgroups.to_csv('../Result_dup/Pgroups.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ctrl1_0\n",
      "ctrl1_1000\n",
      "ctrl1_2000\n",
      "ctrl1_3000\n",
      "Notfound ctrl1_3043\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/site-packages/ipykernel/__main__.py:20: RuntimeWarning: overflow encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ctrl1_4000\n",
      "Notfound ctrl1_4823\n",
      "ctrl1_5000\n",
      "ctrl1_6000\n",
      "ctrl1_7000\n",
      "ctrl1_8000\n",
      "treated1_0\n",
      "treated1_1000\n",
      "Notfound treated1_1095\n",
      "Notfound treated1_1593\n",
      "Notfound treated1_1685\n",
      "treated1_2000\n",
      "Notfound treated1_2054\n",
      "Notfound treated1_2195\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/site-packages/scipy/optimize/minpack.py:715: OptimizeWarning: Covariance of the parameters could not be estimated\n",
      "  category=OptimizeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Notfound treated1_2983\n",
      "treated1_3000\n",
      "Notfound treated1_3010\n",
      "Notfound treated1_3051\n",
      "Notfound treated1_3319\n",
      "Notfound treated1_3689\n",
      "treated1_4000\n",
      "Notfound treated1_4384\n",
      "Notfound treated1_4755\n",
      "treated1_5000\n",
      "treated1_6000\n",
      "Notfound treated1_6320\n",
      "Notfound treated1_6420\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/site-packages/ipykernel/__main__.py:20: RuntimeWarning: invalid value encountered in double_scalars\n",
      "/usr/local/lib/python2.7/site-packages/ipykernel/__main__.py:17: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "/usr/local/lib/python2.7/site-packages/ipykernel/__main__.py:17: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Notfound treated1_6695\n",
      "treated1_7000\n",
      "Notfound treated1_7426\n",
      "Notfound treated1_7718\n",
      "treated1_8000\n",
      "Notfound treated1_8363\n",
      "ctrl2_0\n",
      "Notfound ctrl2_174\n",
      "Notfound ctrl2_916\n",
      "ctrl2_1000\n",
      "Notfound ctrl2_1234\n",
      "Notfound ctrl2_1526\n",
      "Notfound ctrl2_1538\n",
      "Notfound ctrl2_1721\n",
      "ctrl2_2000\n",
      "ctrl2_3000\n",
      "Notfound ctrl2_3085\n",
      "Notfound ctrl2_3108\n",
      "Notfound ctrl2_3212\n",
      "Notfound ctrl2_3767\n",
      "Notfound ctrl2_3874\n",
      "ctrl2_4000\n",
      "Notfound ctrl2_4960\n",
      "ctrl2_5000\n",
      "Notfound ctrl2_5740\n",
      "ctrl2_6000\n",
      "Notfound ctrl2_6695\n",
      "ctrl2_7000\n",
      "ctrl2_8000\n",
      "treated2_0\n",
      "Notfound treated2_151\n",
      "Notfound treated2_209\n",
      "Notfound treated2_412\n",
      "Notfound treated2_672\n",
      "Notfound treated2_916\n",
      "treated2_1000\n",
      "Notfound treated2_1751\n",
      "Notfound treated2_1798\n",
      "Notfound treated2_1984\n",
      "treated2_2000\n",
      "Notfound treated2_2054\n",
      "Notfound treated2_2551\n",
      "Notfound treated2_2574\n",
      "Notfound treated2_2958\n",
      "treated2_3000\n",
      "Notfound treated2_3050\n",
      "Notfound treated2_3077\n",
      "Notfound treated2_3117\n",
      "Notfound treated2_3295\n",
      "Notfound treated2_3399\n",
      "Notfound treated2_3401\n",
      "Notfound treated2_3585\n",
      "Notfound treated2_3868\n",
      "Notfound treated2_3874\n",
      "treated2_4000\n",
      "Notfound treated2_4218\n",
      "Notfound treated2_4257\n",
      "Notfound treated2_4645\n",
      "Notfound treated2_4968\n",
      "treated2_5000\n",
      "Notfound treated2_5388\n",
      "Notfound treated2_5560\n",
      "Notfound treated2_5572\n",
      "treated2_6000\n",
      "Notfound treated2_6054\n",
      "Notfound treated2_6391\n",
      "Notfound treated2_6524\n",
      "Notfound treated2_6605\n",
      "treated2_7000\n",
      "Notfound treated2_7485\n",
      "Notfound treated2_7780\n",
      "Notfound treated2_7996\n",
      "treated2_8000\n",
      "Notfound treated2_8243\n",
      "Notfound treated2_8277\n",
      "Notfound treated2_8618\n"
     ]
    }
   ],
   "source": [
    "ctrl1_fit,ctrl1_param,ctrl1_R,ctrl1_min,ctrl1_infl,ctrl1_slope=fitting(ctrl1norm,temps,startPars,'ctrl1',Pgroups)\n",
    "treated1_fit,treated1_param,treated1_R,treated1_min,treated1_infl,treated1_slope=fitting(treated1norm,temps,startPars,'treated1',Pgroups)\n",
    "ctrl2_fit,ctrl2_param,ctrl2_R,ctrl2_min,ctrl2_infl,ctrl2_slope=fitting(ctrl2norm,temps,startPars,'ctrl2',Pgroups)\n",
    "treated2_fit,treated2_param,treated2_R,treated2_min,treated2_infl,treated2_slope=fitting(treated2norm,temps,startPars,'treated2',Pgroups)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
